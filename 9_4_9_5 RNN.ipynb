{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T12:25:47.105826Z",
     "start_time": "2024-10-21T12:25:47.094830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RNNScratch(d2l.Module):  #@save\n",
    "    \"\"\"The RNN model implemented from scratch.\"\"\"\n",
    "    def __init__(self, num_inputs, num_hiddens, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.W_xh = nn.Parameter(\n",
    "            torch.randn(num_inputs, num_hiddens) * sigma)\n",
    "        self.W_hh = nn.Parameter(\n",
    "            torch.randn(num_hiddens, num_hiddens) * sigma)\n",
    "        self.b_h = nn.Parameter(torch.zeros(num_hiddens))"
   ],
   "id": "863b30044e03da7d",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T12:25:47.573201Z",
     "start_time": "2024-10-21T12:25:47.557206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@d2l.add_to_class(RNNScratch)  #@save\n",
    "def forward(self, inputs, state=None):\n",
    "    if state is None:\n",
    "        # Initial state with shape: (batch_size, num_hiddens)\n",
    "        state = torch.zeros((inputs.shape[1], self.num_hiddens),\n",
    "                          device=inputs.device)\n",
    "    else:\n",
    "        state, = state\n",
    "    outputs = []\n",
    "    for X in inputs:  # Shape of inputs: (num_steps, batch_size, num_inputs)\n",
    "        state = torch.tanh(torch.matmul(X, self.W_xh) +\n",
    "                         torch.matmul(state, self.W_hh) + self.b_h)\n",
    "        outputs.append(state)\n",
    "    return outputs, state"
   ],
   "id": "bf4395cccd96ea1d",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T12:25:47.993151Z",
     "start_time": "2024-10-21T12:25:47.965118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size, num_inputs, num_hiddens, num_steps = 2, 16, 32, 100\n",
    "rnn = RNNScratch(num_inputs, num_hiddens)\n",
    "X = torch.ones((num_steps, batch_size, num_inputs))\n",
    "outputs, state = rnn(X)"
   ],
   "id": "d8759313cc54c00a",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T12:26:04.143552Z",
     "start_time": "2024-10-21T12:26:04.123242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_len(a, n):  #@save\n",
    "    \"\"\"Check the length of a list.\"\"\"\n",
    "    assert len(a) == n, f'list\\'s length {len(a)} != expected length {n}'\n",
    "\n",
    "def check_shape(a, shape):  #@save\n",
    "    \"\"\"Check the shape of a tensor.\"\"\"\n",
    "    assert a.shape == shape, \\\n",
    "            f'tensor\\'s shape {a.shape} != expected shape {shape}'\n",
    "\n",
    "check_len(outputs, num_steps)\n",
    "check_shape(outputs[0], (batch_size, num_hiddens))\n",
    "check_shape(state, (batch_size, num_hiddens))"
   ],
   "id": "d73acb716d367cf9",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T12:26:08.589072Z",
     "start_time": "2024-10-21T12:26:08.577080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RNNLMScratch(d2l.Classifier):  #@save\n",
    "    \"\"\"The RNN-based language model implemented from scratch.\"\"\"\n",
    "    def __init__(self, rnn, vocab_size, lr=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        self.W_hq = nn.Parameter(\n",
    "            torch.randn(\n",
    "                self.rnn.num_hiddens, self.vocab_size) * self.rnn.sigma)\n",
    "        self.b_q = nn.Parameter(torch.zeros(self.vocab_size))\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "        self.plot('ppl', torch.exp(l), train=True)\n",
    "        return l\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "        self.plot('ppl', torch.exp(l), train=False)"
   ],
   "id": "1d37837e7b68b882",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T12:26:16.001599Z",
     "start_time": "2024-10-21T12:26:15.994598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@d2l.add_to_class(RNNLMScratch)  #@save\n",
    "def one_hot(self, X):\n",
    "    # Output shape: (num_steps, batch_size, vocab_size)\n",
    "    return F.one_hot(X.T, self.vocab_size).type(torch.float32)"
   ],
   "id": "69e0dd813ed2f180",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T12:26:20.305210Z",
     "start_time": "2024-10-21T12:26:20.292183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@d2l.add_to_class(RNNLMScratch)  #@save\n",
    "def output_layer(self, rnn_outputs):\n",
    "    outputs = [torch.matmul(H, self.W_hq) + self.b_q for H in rnn_outputs]\n",
    "    return torch.stack(outputs, 1)\n",
    "\n",
    "@d2l.add_to_class(RNNLMScratch)  #@save\n",
    "def forward(self, X, state=None):\n",
    "    embs = self.one_hot(X)\n",
    "    rnn_outputs, _ = self.rnn(embs, state)\n",
    "    return self.output_layer(rnn_outputs)"
   ],
   "id": "3c24e8d31d6526b4",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T12:26:28.523149Z",
     "start_time": "2024-10-21T12:26:28.503150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = RNNLMScratch(rnn, num_inputs)\n",
    "outputs = model(torch.ones((batch_size, num_steps), dtype=torch.int64))\n",
    "check_shape(outputs, (batch_size, num_steps, num_inputs))"
   ],
   "id": "1089274f0a016d83",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T12:26:36.310101Z",
     "start_time": "2024-10-21T12:26:36.290670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@d2l.add_to_class(d2l.Trainer)  #@save\n",
    "def clip_gradients(self, grad_clip_val, model):\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > grad_clip_val:\n",
    "        for param in params:\n",
    "            param.grad[:] *= grad_clip_val / norm"
   ],
   "id": "928fb4588838032d",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = d2l.TimeMachine(batch_size=1024, num_steps=32)\n",
    "rnn = RNNScratch(num_inputs=len(data.vocab), num_hiddens=32)\n",
    "model = RNNLMScratch(rnn=rnn, vocab_size=len(data.vocab), lr=1)\n",
    "trainer = d2l.Trainer(max_epochs=100, gradient_clip_val=1, num_gpus=1)\n",
    "trainer.fit(model, data)"
   ],
   "id": "63a3f9c68a2405fd",
   "execution_count": 74,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T12:41:28.948821Z",
     "start_time": "2024-10-21T12:41:28.928791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@d2l.add_to_class(RNNLMScratch) #@save\n",
    "def predict(self, prefix, num_preds, vocab, device=None):\n",
    "    state, outputs = None, [vocab[prefix[0]]]\n",
    "    for i in range(len(prefix) + num_preds - 1):\n",
    "        X = torch.tensor([[outputs[-1]]])\n",
    "        embs = self.one_hot(X)\n",
    "        rnn_outputs, state = self.rnn(embs, state)\n",
    "        if  i < len(prefix) - 1: #Warm-up period\n",
    "            outputs.append(vocab[prefix[i + 1]])\n",
    "        else: # Predict num_preds steps\n",
    "            Y = self.output_layer(rnn_outputs)\n",
    "            outputs.append(int(Y.argmax(axis=2).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[idx] for idx in outputs]) "
   ],
   "id": "8a1d24650af4a09b",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T12:42:34.089150Z",
     "start_time": "2024-10-21T12:42:34.038018Z"
    }
   },
   "cell_type": "code",
   "source": "model.predict(' the', 200, data.vocab)",
   "id": "c15bddac330cee06",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "777b150af546a604"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
